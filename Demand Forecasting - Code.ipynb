{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea0f1b18-3387-42b6-87d0-7af66427d7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "253bba5b-e659-4dd3-92b9-ccda62cc4c46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Orders_Date</th>\n",
       "      <th>Sales_Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-02-01</td>\n",
       "      <td>376832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-03-01</td>\n",
       "      <td>481754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-04-01</td>\n",
       "      <td>240192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-05-01</td>\n",
       "      <td>138704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-06-01</td>\n",
       "      <td>193440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2020-07-01</td>\n",
       "      <td>321818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2020-08-01</td>\n",
       "      <td>202245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2020-09-01</td>\n",
       "      <td>313422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2020-10-01</td>\n",
       "      <td>396599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2020-11-01</td>\n",
       "      <td>377673</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Orders_Date  Sales_Volume\n",
       "0  2020-02-01        376832\n",
       "1  2020-03-01        481754\n",
       "2  2020-04-01        240192\n",
       "3  2020-05-01        138704\n",
       "4  2020-06-01        193440\n",
       "5  2020-07-01        321818\n",
       "6  2020-08-01        202245\n",
       "7  2020-09-01        313422\n",
       "8  2020-10-01        396599\n",
       "9  2020-11-01        377673"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_excel(\"Demand_Forecasting_Monthly_Data.xlsx\")\n",
    "df.drop('Data',axis=1,inplace=True)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "485e844f-49ca-44a3-ba64-59db4f292ec7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Orders_Date', 'Sales_Volume'], dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e8ea71c9-142e-4212-bdde-51e61dd30128",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Orders_Date  Actual    Holt-winter  Accuracy_SimpleExpo\n",
      "0  2023-10-01  352135  243130.771279            69.044762\n",
      "1  2023-11-01  349500  268466.416779            76.814425\n",
      "2  2023-12-01  237928  293604.015443           123.400363\n",
      "3  2024-01-01  302400  287959.839676            95.224815\n",
      "4  2024-02-01  287972  297327.709509           103.248826\n",
      "5  2024-03-01  253875  301408.121383           118.723041\n",
      "6  2024-04-01  285937  294932.987003           103.146143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Charan\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency MS will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\Charan\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\holtwinters\\model.py:918: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Charan\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency MS will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\Charan\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\holtwinters\\model.py:918: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Charan\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency MS will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\Charan\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\holtwinters\\model.py:918: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Charan\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency MS will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\Charan\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\holtwinters\\model.py:918: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Charan\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency MS will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\Charan\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\holtwinters\\model.py:918: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Charan\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency MS will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\Charan\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\holtwinters\\model.py:918: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Charan\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency MS will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\Charan\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\holtwinters\\model.py:918: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from statsmodels.tsa.api import Holt\n",
    "\n",
    "df['Orders_Date'] = pd.to_datetime(df['Orders_Date'])\n",
    "df = df[df['Orders_Date'] > '2022-04-01']\n",
    "dates = pd.date_range(start='2023-10-01', end='2024-04-01', freq='MS')\n",
    "\n",
    "final_result = []\n",
    "\n",
    "for da in dates:\n",
    "    data = {}\n",
    "    Train = df[df['Orders_Date'] < da]\n",
    "    Test = df[df['Orders_Date'] == da]\n",
    "    if Test.empty:\n",
    "        continue\n",
    "    Train.set_index('Orders_Date', inplace=True)\n",
    "    actual_value = Test['Sales_Volume'].values[0]\n",
    "    model = Holt(\n",
    "        Train['Sales_Volume'], \n",
    "        damped_trend=True, \n",
    "        exponential=True, \n",
    "        initialization_method=\"estimated\"\n",
    "    ).fit(smoothing_level=0.2, smoothing_trend=0.3)\n",
    "    forecast = model.forecast(1)\n",
    "    predicted_value = forecast.iloc[0]\n",
    "    data[\"Orders_Date\"] = da\n",
    "    data['Actual'] = actual_value\n",
    "    data['Holt-winter'] = predicted_value\n",
    "    data['Accuracy_SimpleExpo'] = (predicted_value * 100) / actual_value\n",
    "    final_result.append(data)\n",
    "\n",
    "final_TotalOrders = pd.DataFrame(final_result)\n",
    "print(final_TotalOrders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "82921cba-41b2-4122-b3b5-d27cd946eee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing stepwise search to minimize aic\n",
      " ARIMA(2,0,2)(1,0,1)[4] intercept   : AIC=inf, Time=1.03 sec\n",
      " ARIMA(0,0,0)(0,0,0)[4] intercept   : AIC=432.982, Time=0.03 sec\n",
      " ARIMA(1,0,0)(1,0,0)[4] intercept   : AIC=433.831, Time=0.11 sec\n",
      " ARIMA(0,0,1)(0,0,1)[4] intercept   : AIC=433.251, Time=0.06 sec\n",
      " ARIMA(0,0,0)(0,0,0)[4]             : AIC=478.000, Time=0.00 sec\n",
      " ARIMA(0,0,0)(1,0,0)[4] intercept   : AIC=434.863, Time=0.01 sec\n",
      " ARIMA(0,0,0)(0,0,1)[4] intercept   : AIC=431.718, Time=0.04 sec\n",
      " ARIMA(0,0,0)(1,0,1)[4] intercept   : AIC=433.717, Time=0.04 sec\n",
      " ARIMA(0,0,0)(0,0,2)[4] intercept   : AIC=433.716, Time=0.04 sec\n",
      " ARIMA(0,0,0)(1,0,2)[4] intercept   : AIC=435.715, Time=0.04 sec\n",
      " ARIMA(1,0,0)(0,0,1)[4] intercept   : AIC=432.994, Time=0.02 sec\n",
      " ARIMA(1,0,1)(0,0,1)[4] intercept   : AIC=434.358, Time=0.09 sec\n",
      " ARIMA(0,0,0)(0,0,1)[4]             : AIC=inf, Time=0.03 sec\n",
      "\n",
      "Best model:  ARIMA(0,0,0)(0,0,1)[4] intercept\n",
      "Total fit time: 1.603 seconds\n",
      "  Orders_Date  Actual         SARIMA  Accuracy_SimpleExpo\n",
      "0  2023-10-01  352135  288167.670899            81.834430\n",
      "1  2023-11-01  349500  326367.614075            93.381292\n",
      "2  2023-12-01  237928  325566.378838           136.833991\n",
      "3  2024-01-01  302400  219222.818617            72.494318\n",
      "4  2024-02-01  287972  280973.441529            97.569709\n",
      "5  2024-03-01  253875  268169.561973           105.630551\n",
      "6  2024-04-01  285937  236391.527097            82.672591\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from pmdarima import auto_arima\n",
    "\n",
    "Train = df[df['Orders_Date'] <= '2023-09-01']\n",
    "Train.set_index('Orders_Date', inplace=True)\n",
    "Train.index = pd.DatetimeIndex(Train.index).to_period('M')\n",
    "auto_arima(Train['Sales_Volume'],seasonal=True,trace=True,m=4,suppress_warnings=True)\n",
    "\n",
    "final_result=[]\n",
    "for da in dates:\n",
    "    data = {}\n",
    "    Train = df[df['Orders_Date'] < da]\n",
    "    Train.set_index('Orders_Date', inplace=True)\n",
    "    Train.index = pd.DatetimeIndex(Train.index).to_period('M')\n",
    "    Test = df[df['Orders_Date'] == da]\n",
    "    \n",
    "    data[\"Orders_Date\"] = da\n",
    "    data['Actual'] = Test['Sales_Volume'].values[0]\n",
    "\n",
    "    model=SARIMAX(Train['Sales_Volume'],order=(1,0,0),seasonal_order=(0,0,0,4)).fit()\n",
    "    forecast=model.predict(start=len(Train),end=len(Train)+1,dynamic=True)\n",
    "    Result = forecast.values[0]\n",
    "    \n",
    "    data[\"SARIMA\"] = Result\n",
    "    data['Accuracy_SimpleExpo'] = ((Result * 100) / Test['Sales_Volume'].values[0])\n",
    "    final_result.append(data)\n",
    "\n",
    "final_TotalOrders = pd.DataFrame(final_result)\n",
    "print(final_TotalOrders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2b9b4c1e-e654-4acf-b2bb-0c73978ff9d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Charan\\anaconda3\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "09:42:02 - cmdstanpy - INFO - Chain [1] start processing\n",
      "09:42:02 - cmdstanpy - INFO - Chain [1] done processing\n",
      "C:\\Users\\Charan\\anaconda3\\Lib\\site-packages\\prophet\\forecaster.py:1854: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  dates = pd.date_range(\n",
      "09:42:02 - cmdstanpy - INFO - Chain [1] start processing\n",
      "09:42:02 - cmdstanpy - INFO - Chain [1] done processing\n",
      "C:\\Users\\Charan\\anaconda3\\Lib\\site-packages\\prophet\\forecaster.py:1854: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  dates = pd.date_range(\n",
      "09:42:03 - cmdstanpy - INFO - Chain [1] start processing\n",
      "09:42:03 - cmdstanpy - INFO - Chain [1] done processing\n",
      "C:\\Users\\Charan\\anaconda3\\Lib\\site-packages\\prophet\\forecaster.py:1854: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  dates = pd.date_range(\n",
      "09:42:03 - cmdstanpy - INFO - Chain [1] start processing\n",
      "09:42:03 - cmdstanpy - INFO - Chain [1] done processing\n",
      "C:\\Users\\Charan\\anaconda3\\Lib\\site-packages\\prophet\\forecaster.py:1854: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  dates = pd.date_range(\n",
      "09:42:03 - cmdstanpy - INFO - Chain [1] start processing\n",
      "09:42:03 - cmdstanpy - INFO - Chain [1] done processing\n",
      "C:\\Users\\Charan\\anaconda3\\Lib\\site-packages\\prophet\\forecaster.py:1854: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  dates = pd.date_range(\n",
      "09:42:03 - cmdstanpy - INFO - Chain [1] start processing\n",
      "09:42:03 - cmdstanpy - INFO - Chain [1] done processing\n",
      "C:\\Users\\Charan\\anaconda3\\Lib\\site-packages\\prophet\\forecaster.py:1854: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  dates = pd.date_range(\n",
      "09:42:04 - cmdstanpy - INFO - Chain [1] start processing\n",
      "09:42:04 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Orders_Date  Actual        Prophet  Accuracy_SimpleExpo\n",
      "0  2023-10-01  352135  252188.941964            71.617119\n",
      "1  2023-11-01  349500  277156.608546            79.300889\n",
      "2  2023-12-01  237928  296432.229661           124.589048\n",
      "3  2024-01-01  302400  284386.003107            94.042990\n",
      "4  2024-02-01  287972  289376.095718           100.487581\n",
      "5  2024-03-01  253875  288239.959405           113.536173\n",
      "6  2024-04-01  285937  283391.728517            99.109849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Charan\\anaconda3\\Lib\\site-packages\\prophet\\forecaster.py:1854: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  dates = pd.date_range(\n"
     ]
    }
   ],
   "source": [
    "from prophet import Prophet\n",
    "\n",
    "dates = ['2023-10-01', '2023-11-01', '2023-12-01', '2024-01-01', '2024-02-01', '2024-03-01','2024-04-01']\n",
    "\n",
    "final_result=[]\n",
    "for da in dates:\n",
    "    data = {}\n",
    "    Train = df[(df['Orders_Date']>='2022-08-01') & (df['Orders_Date']<da)]\n",
    "    Train=Train.rename(columns={'Orders_Date' : 'ds', 'Sales_Volume' : 'y'})\n",
    "    Test=df[(df['Orders_Date']==da)]\n",
    "    data[\"Orders_Date\"] = da\n",
    "    data['Actual'] = Test['Sales_Volume'].values[0]\n",
    "\n",
    "    model = Prophet()\n",
    "    model.fit(Train)\n",
    "    future=model.make_future_dataframe(periods=2,freq='M').tail(2)\n",
    "    forecast=model.predict(future)\n",
    "    forecast[['ds','yhat']]\n",
    "\n",
    "    Result=sum(forecast['yhat'])/len(forecast)\n",
    "    data[\"Prophet\"] = Result\n",
    "    data['Accuracy_SimpleExpo'] = ((Result * 100) / Test['Sales_Volume'].values[0])\n",
    "    final_result.append(data)\n",
    "\n",
    "final_TotalOrders = pd.DataFrame(final_result)\n",
    "print(final_TotalOrders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "06ab33bb-66c2-4786-bbe3-92a397b7eaf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name            | Type             | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | criterion       | MSELoss          | 0      | train\n",
      "1 | train_criterion | MSELoss          | 0      | train\n",
      "2 | val_criterion   | MSELoss          | 0      | train\n",
      "3 | train_metrics   | MetricCollection | 0      | train\n",
      "4 | val_metrics     | MetricCollection | 0      | train\n",
      "5 | stacks          | ModuleList       | 6.1 M  | train\n",
      "-------------------------------------------------------------\n",
      "6.1 M     Trainable params\n",
      "1.3 K     Non-trainable params\n",
      "6.1 M     Total params\n",
      "24.217    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00,  4.62it/s, train_loss=3.52e+4]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00,  4.62it/s, train_loss=3.52e+4]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 23.71it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name            | Type             | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | criterion       | MSELoss          | 0      | train\n",
      "1 | train_criterion | MSELoss          | 0      | train\n",
      "2 | val_criterion   | MSELoss          | 0      | train\n",
      "3 | train_metrics   | MetricCollection | 0      | train\n",
      "4 | val_metrics     | MetricCollection | 0      | train\n",
      "5 | stacks          | ModuleList       | 6.1 M  | train\n",
      "-------------------------------------------------------------\n",
      "6.1 M     Trainable params\n",
      "1.3 K     Non-trainable params\n",
      "6.1 M     Total params\n",
      "24.217    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00,  5.22it/s, train_loss=2.58e+4]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00,  4.82it/s, train_loss=2.58e+4]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 31.85it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name            | Type             | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | criterion       | MSELoss          | 0      | train\n",
      "1 | train_criterion | MSELoss          | 0      | train\n",
      "2 | val_criterion   | MSELoss          | 0      | train\n",
      "3 | train_metrics   | MetricCollection | 0      | train\n",
      "4 | val_metrics     | MetricCollection | 0      | train\n",
      "5 | stacks          | ModuleList       | 6.1 M  | train\n",
      "-------------------------------------------------------------\n",
      "6.1 M     Trainable params\n",
      "1.3 K     Non-trainable params\n",
      "6.1 M     Total params\n",
      "24.217    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00,  5.21it/s, train_loss=6e+4]   "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00,  5.14it/s, train_loss=6e+4]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 36.78it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name            | Type             | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | criterion       | MSELoss          | 0      | train\n",
      "1 | train_criterion | MSELoss          | 0      | train\n",
      "2 | val_criterion   | MSELoss          | 0      | train\n",
      "3 | train_metrics   | MetricCollection | 0      | train\n",
      "4 | val_metrics     | MetricCollection | 0      | train\n",
      "5 | stacks          | ModuleList       | 6.1 M  | train\n",
      "-------------------------------------------------------------\n",
      "6.1 M     Trainable params\n",
      "1.3 K     Non-trainable params\n",
      "6.1 M     Total params\n",
      "24.217    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00,  5.03it/s, train_loss=7.32e+4]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00,  4.81it/s, train_loss=7.32e+4]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 55.39it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name            | Type             | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | criterion       | MSELoss          | 0      | train\n",
      "1 | train_criterion | MSELoss          | 0      | train\n",
      "2 | val_criterion   | MSELoss          | 0      | train\n",
      "3 | train_metrics   | MetricCollection | 0      | train\n",
      "4 | val_metrics     | MetricCollection | 0      | train\n",
      "5 | stacks          | ModuleList       | 6.1 M  | train\n",
      "-------------------------------------------------------------\n",
      "6.1 M     Trainable params\n",
      "1.3 K     Non-trainable params\n",
      "6.1 M     Total params\n",
      "24.217    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00,  5.71it/s, train_loss=4.68e+5]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00,  5.71it/s, train_loss=4.68e+5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 29.58it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name            | Type             | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | criterion       | MSELoss          | 0      | train\n",
      "1 | train_criterion | MSELoss          | 0      | train\n",
      "2 | val_criterion   | MSELoss          | 0      | train\n",
      "3 | train_metrics   | MetricCollection | 0      | train\n",
      "4 | val_metrics     | MetricCollection | 0      | train\n",
      "5 | stacks          | ModuleList       | 6.1 M  | train\n",
      "-------------------------------------------------------------\n",
      "6.1 M     Trainable params\n",
      "1.3 K     Non-trainable params\n",
      "6.1 M     Total params\n",
      "24.217    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00,  5.35it/s, train_loss=5.68e+5]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00,  5.35it/s, train_loss=5.68e+5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 38.05it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name            | Type             | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | criterion       | MSELoss          | 0      | train\n",
      "1 | train_criterion | MSELoss          | 0      | train\n",
      "2 | val_criterion   | MSELoss          | 0      | train\n",
      "3 | train_metrics   | MetricCollection | 0      | train\n",
      "4 | val_metrics     | MetricCollection | 0      | train\n",
      "5 | stacks          | ModuleList       | 6.1 M  | train\n",
      "-------------------------------------------------------------\n",
      "6.1 M     Trainable params\n",
      "1.3 K     Non-trainable params\n",
      "6.1 M     Total params\n",
      "24.217    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00,  5.77it/s, train_loss=7.15e+5]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00,  5.28it/s, train_loss=7.15e+5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 165.19it/s]\n",
      "  Orders_Date  Actual         NBEATS  Accuracy_NBEATS\n",
      "0  2023-10-01  352135  229738.402951        65.241570\n",
      "1  2023-11-01  349500  181389.135304        51.899610\n",
      "2  2023-12-01  237928  276722.418562       116.305109\n",
      "3  2024-01-01  302400  292350.245908        96.676669\n",
      "4  2024-02-01  287972  248869.685493        86.421487\n",
      "5  2024-03-01  253875  235300.221913        92.683495\n",
      "6  2024-04-01  285937  278563.418646        97.421257\n"
     ]
    }
   ],
   "source": [
    "from darts import TimeSeries\n",
    "from darts.models import NBEATSModel\n",
    "import pandas as pd\n",
    "\n",
    "dates = ['2023-10-01', '2023-11-01', '2023-12-01', '2024-01-01', '2024-02-01', '2024-03-01', '2024-04-01']\n",
    "\n",
    "final_result = []\n",
    "for da in dates:\n",
    "    data = {}\n",
    "    Train = df.copy()\n",
    "    series = TimeSeries.from_dataframe(Train, time_col='Orders_Date', value_cols='Sales_Volume')\n",
    "\n",
    "    train, val = series.split_before(pd.Timestamp(da))\n",
    "    Test = df[df['Orders_Date'] == da]\n",
    "    data['Orders_Date'] = da\n",
    "    data['Actual'] = Test['Sales_Volume'].values[0]\n",
    "\n",
    "    model = NBEATSModel(input_chunk_length=6, output_chunk_length=6, n_epochs=100, activation='ReLU')\n",
    "    model.fit(train)\n",
    "    forecast = model.predict(1)\n",
    "    Result = forecast.pd_series().tolist()\n",
    "\n",
    "    data[\"NBEATS\"] = Result[0]  # Assuming you want the first value of the forecast\n",
    "    data['Accuracy_NBEATS'] = ((Result[0] * 100) / Test['Sales_Volume'].values[0])\n",
    "    final_result.append(data)\n",
    "\n",
    "final_TotalOrders = pd.DataFrame(final_result)\n",
    "print(final_TotalOrders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4083c9d7-b59e-4bc7-845c-5b31b8bc065a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name            | Type             | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | criterion       | MSELoss          | 0      | train\n",
      "1 | train_criterion | MSELoss          | 0      | train\n",
      "2 | val_criterion   | MSELoss          | 0      | train\n",
      "3 | train_metrics   | MetricCollection | 0      | train\n",
      "4 | val_metrics     | MetricCollection | 0      | train\n",
      "5 | stacks          | ModuleList       | 6.1 M  | train\n",
      "-------------------------------------------------------------\n",
      "6.1 M     Trainable params\n",
      "1.3 K     Non-trainable params\n",
      "6.1 M     Total params\n",
      "24.217    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00,  7.21it/s, train_loss=1.13e+4]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00,  7.04it/s, train_loss=1.13e+4]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 54.03it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name            | Type             | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | criterion       | MSELoss          | 0      | train\n",
      "1 | train_criterion | MSELoss          | 0      | train\n",
      "2 | val_criterion   | MSELoss          | 0      | train\n",
      "3 | train_metrics   | MetricCollection | 0      | train\n",
      "4 | val_metrics     | MetricCollection | 0      | train\n",
      "5 | stacks          | ModuleList       | 6.1 M  | train\n",
      "-------------------------------------------------------------\n",
      "6.1 M     Trainable params\n",
      "1.3 K     Non-trainable params\n",
      "6.1 M     Total params\n",
      "24.217    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00,  5.45it/s, train_loss=1.55e+4]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00,  5.03it/s, train_loss=1.55e+4]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 60.50it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name            | Type             | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | criterion       | MSELoss          | 0      | train\n",
      "1 | train_criterion | MSELoss          | 0      | train\n",
      "2 | val_criterion   | MSELoss          | 0      | train\n",
      "3 | train_metrics   | MetricCollection | 0      | train\n",
      "4 | val_metrics     | MetricCollection | 0      | train\n",
      "5 | stacks          | ModuleList       | 6.1 M  | train\n",
      "-------------------------------------------------------------\n",
      "6.1 M     Trainable params\n",
      "1.3 K     Non-trainable params\n",
      "6.1 M     Total params\n",
      "24.217    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00,  3.43it/s, train_loss=6.73e+4]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00,  3.32it/s, train_loss=6.73e+4]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 59.73it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name            | Type             | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | criterion       | MSELoss          | 0      | train\n",
      "1 | train_criterion | MSELoss          | 0      | train\n",
      "2 | val_criterion   | MSELoss          | 0      | train\n",
      "3 | train_metrics   | MetricCollection | 0      | train\n",
      "4 | val_metrics     | MetricCollection | 0      | train\n",
      "5 | stacks          | ModuleList       | 6.1 M  | train\n",
      "-------------------------------------------------------------\n",
      "6.1 M     Trainable params\n",
      "1.3 K     Non-trainable params\n",
      "6.1 M     Total params\n",
      "24.217    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00,  6.11it/s, train_loss=1.42e+5]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00,  5.64it/s, train_loss=1.42e+5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 48.92it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name            | Type             | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | criterion       | MSELoss          | 0      | train\n",
      "1 | train_criterion | MSELoss          | 0      | train\n",
      "2 | val_criterion   | MSELoss          | 0      | train\n",
      "3 | train_metrics   | MetricCollection | 0      | train\n",
      "4 | val_metrics     | MetricCollection | 0      | train\n",
      "5 | stacks          | ModuleList       | 6.1 M  | train\n",
      "-------------------------------------------------------------\n",
      "6.1 M     Trainable params\n",
      "1.3 K     Non-trainable params\n",
      "6.1 M     Total params\n",
      "24.217    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00,  6.21it/s, train_loss=6.33e+5]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00,  5.66it/s, train_loss=6.33e+5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 65.65it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name            | Type             | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | criterion       | MSELoss          | 0      | train\n",
      "1 | train_criterion | MSELoss          | 0      | train\n",
      "2 | val_criterion   | MSELoss          | 0      | train\n",
      "3 | train_metrics   | MetricCollection | 0      | train\n",
      "4 | val_metrics     | MetricCollection | 0      | train\n",
      "5 | stacks          | ModuleList       | 6.1 M  | train\n",
      "-------------------------------------------------------------\n",
      "6.1 M     Trainable params\n",
      "1.3 K     Non-trainable params\n",
      "6.1 M     Total params\n",
      "24.217    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00,  5.88it/s, train_loss=1.47e+6]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00,  5.49it/s, train_loss=1.47e+6]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 41.41it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name            | Type             | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | criterion       | MSELoss          | 0      | train\n",
      "1 | train_criterion | MSELoss          | 0      | train\n",
      "2 | val_criterion   | MSELoss          | 0      | train\n",
      "3 | train_metrics   | MetricCollection | 0      | train\n",
      "4 | val_metrics     | MetricCollection | 0      | train\n",
      "5 | stacks          | ModuleList       | 6.1 M  | train\n",
      "-------------------------------------------------------------\n",
      "6.1 M     Trainable params\n",
      "1.3 K     Non-trainable params\n",
      "6.1 M     Total params\n",
      "24.217    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00,  2.91it/s, train_loss=1.46e+6]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00,  2.86it/s, train_loss=1.46e+6]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 58.01it/s] \n",
      "  Orders_Date  Actual          NHiTS  Accuracy_NBEATS\n",
      "0  2023-10-01  352135  226477.932848        64.315655\n",
      "1  2023-11-01  349500  180509.889531        51.648037\n",
      "2  2023-12-01  237928  281722.266448       118.406521\n",
      "3  2024-01-01  302400  296794.144532        98.146212\n",
      "4  2024-02-01  287972  230316.518999        79.978789\n",
      "5  2024-03-01  253875  243314.854763        95.840415\n",
      "6  2024-04-01  285937  297951.905830       104.201942\n"
     ]
    }
   ],
   "source": [
    "from darts import TimeSeries\n",
    "from darts.models import NHiTSModel\n",
    "import pandas as pd\n",
    "\n",
    "dates = ['2023-10-01', '2023-11-01', '2023-12-01', '2024-01-01', '2024-02-01', '2024-03-01', '2024-04-01']\n",
    "\n",
    "final_result = []\n",
    "for da in dates:\n",
    "    data = {}\n",
    "    Train = df.copy()\n",
    "    series = TimeSeries.from_dataframe(Train, time_col='Orders_Date', value_cols='Sales_Volume')\n",
    "\n",
    "    train, val = series.split_before(pd.Timestamp(da))\n",
    "    Test = df[df['Orders_Date'] == da]\n",
    "    data['Orders_Date'] = da\n",
    "    data['Actual'] = Test['Sales_Volume'].values[0]\n",
    "\n",
    "    model = NBEATSModel(input_chunk_length=6, output_chunk_length=6, n_epochs=100, activation='ReLU')\n",
    "    model.fit(train)\n",
    "    forecast = model.predict(1)\n",
    "    Result = forecast.pd_series().tolist()\n",
    "\n",
    "    data[\"NHiTS\"] = Result[0]  # Assuming you want the first value of the forecast\n",
    "    data['Accuracy_NBEATS'] = ((Result[0] * 100) / Test['Sales_Volume'].values[0])\n",
    "    final_result.append(data)\n",
    "\n",
    "final_TotalOrders = pd.DataFrame(final_result)\n",
    "print(final_TotalOrders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "72f849e4-d110-438b-8c92-c3d86134b633",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name             | Type             | Params | Mode \n",
      "--------------------------------------------------------------\n",
      "0 | criterion        | MSELoss          | 0      | train\n",
      "1 | train_criterion  | MSELoss          | 0      | train\n",
      "2 | val_criterion    | MSELoss          | 0      | train\n",
      "3 | train_metrics    | MetricCollection | 0      | train\n",
      "4 | val_metrics      | MetricCollection | 0      | train\n",
      "5 | encoders         | Sequential       | 18.3 K | train\n",
      "6 | decoders         | Sequential       | 41.3 K | train\n",
      "7 | temporal_decoder | _ResidualBlock   | 594    | train\n",
      "8 | lookback_skip    | Linear           | 42     | train\n",
      "--------------------------------------------------------------\n",
      "60.2 K    Trainable params\n",
      "0         Non-trainable params\n",
      "60.2 K    Total params\n",
      "0.241     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 56.05it/s, train_loss=3.04e+8] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 56.05it/s, train_loss=3.04e+8]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 215.78it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name             | Type             | Params | Mode \n",
      "--------------------------------------------------------------\n",
      "0 | criterion        | MSELoss          | 0      | train\n",
      "1 | train_criterion  | MSELoss          | 0      | train\n",
      "2 | val_criterion    | MSELoss          | 0      | train\n",
      "3 | train_metrics    | MetricCollection | 0      | train\n",
      "4 | val_metrics      | MetricCollection | 0      | train\n",
      "5 | encoders         | Sequential       | 18.3 K | train\n",
      "6 | decoders         | Sequential       | 41.3 K | train\n",
      "7 | temporal_decoder | _ResidualBlock   | 594    | train\n",
      "8 | lookback_skip    | Linear           | 42     | train\n",
      "--------------------------------------------------------------\n",
      "60.2 K    Trainable params\n",
      "0         Non-trainable params\n",
      "60.2 K    Total params\n",
      "0.241     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 79.62it/s, train_loss=6.09e+8]  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 76.23it/s, train_loss=6.09e+8]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 211.44it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name             | Type             | Params | Mode \n",
      "--------------------------------------------------------------\n",
      "0 | criterion        | MSELoss          | 0      | train\n",
      "1 | train_criterion  | MSELoss          | 0      | train\n",
      "2 | val_criterion    | MSELoss          | 0      | train\n",
      "3 | train_metrics    | MetricCollection | 0      | train\n",
      "4 | val_metrics      | MetricCollection | 0      | train\n",
      "5 | encoders         | Sequential       | 18.3 K | train\n",
      "6 | decoders         | Sequential       | 41.3 K | train\n",
      "7 | temporal_decoder | _ResidualBlock   | 594    | train\n",
      "8 | lookback_skip    | Linear           | 42     | train\n",
      "--------------------------------------------------------------\n",
      "60.2 K    Trainable params\n",
      "0         Non-trainable params\n",
      "60.2 K    Total params\n",
      "0.241     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 125.88it/s, train_loss=1.27e+9] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 74.58it/s, train_loss=1.27e+9] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 177.26it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name             | Type             | Params | Mode \n",
      "--------------------------------------------------------------\n",
      "0 | criterion        | MSELoss          | 0      | train\n",
      "1 | train_criterion  | MSELoss          | 0      | train\n",
      "2 | val_criterion    | MSELoss          | 0      | train\n",
      "3 | train_metrics    | MetricCollection | 0      | train\n",
      "4 | val_metrics      | MetricCollection | 0      | train\n",
      "5 | encoders         | Sequential       | 18.3 K | train\n",
      "6 | decoders         | Sequential       | 41.3 K | train\n",
      "7 | temporal_decoder | _ResidualBlock   | 594    | train\n",
      "8 | lookback_skip    | Linear           | 42     | train\n",
      "--------------------------------------------------------------\n",
      "60.2 K    Trainable params\n",
      "0         Non-trainable params\n",
      "60.2 K    Total params\n",
      "0.241     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 73.04it/s, train_loss=1.28e+9]  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 61.96it/s, train_loss=1.28e+9]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name             | Type             | Params | Mode \n",
      "--------------------------------------------------------------\n",
      "0 | criterion        | MSELoss          | 0      | train\n",
      "1 | train_criterion  | MSELoss          | 0      | train\n",
      "2 | val_criterion    | MSELoss          | 0      | train\n",
      "3 | train_metrics    | MetricCollection | 0      | train\n",
      "4 | val_metrics      | MetricCollection | 0      | train\n",
      "5 | encoders         | Sequential       | 18.3 K | train\n",
      "6 | decoders         | Sequential       | 41.3 K | train\n",
      "7 | temporal_decoder | _ResidualBlock   | 594    | train\n",
      "8 | lookback_skip    | Linear           | 42     | train\n",
      "--------------------------------------------------------------\n",
      "60.2 K    Trainable params\n",
      "0         Non-trainable params\n",
      "60.2 K    Total params\n",
      "0.241     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 41.71it/s, train_loss=1.08e+9]  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 41.71it/s, train_loss=1.08e+9]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 166.47it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name             | Type             | Params | Mode \n",
      "--------------------------------------------------------------\n",
      "0 | criterion        | MSELoss          | 0      | train\n",
      "1 | train_criterion  | MSELoss          | 0      | train\n",
      "2 | val_criterion    | MSELoss          | 0      | train\n",
      "3 | train_metrics    | MetricCollection | 0      | train\n",
      "4 | val_metrics      | MetricCollection | 0      | train\n",
      "5 | encoders         | Sequential       | 18.3 K | train\n",
      "6 | decoders         | Sequential       | 41.3 K | train\n",
      "7 | temporal_decoder | _ResidualBlock   | 594    | train\n",
      "8 | lookback_skip    | Linear           | 42     | train\n",
      "--------------------------------------------------------------\n",
      "60.2 K    Trainable params\n",
      "0         Non-trainable params\n",
      "60.2 K    Total params\n",
      "0.241     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 57.83it/s, train_loss=2.41e+9] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 51.00it/s, train_loss=2.41e+9]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 134.59it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name             | Type             | Params | Mode \n",
      "--------------------------------------------------------------\n",
      "0 | criterion        | MSELoss          | 0      | train\n",
      "1 | train_criterion  | MSELoss          | 0      | train\n",
      "2 | val_criterion    | MSELoss          | 0      | train\n",
      "3 | train_metrics    | MetricCollection | 0      | train\n",
      "4 | val_metrics      | MetricCollection | 0      | train\n",
      "5 | encoders         | Sequential       | 18.3 K | train\n",
      "6 | decoders         | Sequential       | 41.3 K | train\n",
      "7 | temporal_decoder | _ResidualBlock   | 594    | train\n",
      "8 | lookback_skip    | Linear           | 42     | train\n",
      "--------------------------------------------------------------\n",
      "60.2 K    Trainable params\n",
      "0         Non-trainable params\n",
      "60.2 K    Total params\n",
      "0.241     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 62.72it/s, train_loss=2.05e+9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 54.51it/s, train_loss=2.05e+9]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 111.42it/s]\n",
      "  Orders_Date  Actual           TiDE  Accuracy_NBEATS\n",
      "0  2023-10-01  352135  212895.027340        60.458355\n",
      "1  2023-11-01  349500  179938.165214        51.484454\n",
      "2  2023-12-01  237928  299892.107233       126.043218\n",
      "3  2024-01-01  302400  318436.894067       105.303206\n",
      "4  2024-02-01  287972  226825.703318        78.766583\n",
      "5  2024-03-01  253875  268120.069780       105.611057\n",
      "6  2024-04-01  285937  303379.076582       106.099972\n"
     ]
    }
   ],
   "source": [
    "from darts import TimeSeries\n",
    "from darts.models import TiDEModel\n",
    "import pandas as pd\n",
    "\n",
    "dates = ['2023-10-01', '2023-11-01', '2023-12-01', '2024-01-01', '2024-02-01', '2024-03-01', '2024-04-01']\n",
    "\n",
    "final_result = []\n",
    "for da in dates:\n",
    "    data = {}\n",
    "    Train = df.copy()\n",
    "    series = TimeSeries.from_dataframe(Train, time_col='Orders_Date', value_cols='Sales_Volume')\n",
    "\n",
    "    train, val = series.split_before(pd.Timestamp(da))\n",
    "    Test = df[df['Orders_Date'] == da]\n",
    "    data['Orders_Date'] = da\n",
    "    data['Actual'] = Test['Sales_Volume'].values[0]\n",
    "\n",
    "    model = TiDEModel(input_chunk_length=6, output_chunk_length=6, n_epochs=100)\n",
    "    model.fit(train)\n",
    "    forecast = model.predict(1)\n",
    "    Result = forecast.pd_series().tolist()\n",
    "\n",
    "    data[\"TiDE\"] = Result[0]  # Assuming you want the first value of the forecast\n",
    "    data['Accuracy_NBEATS'] = ((Result[0] * 100) / Test['Sales_Volume'].values[0])\n",
    "    final_result.append(data)\n",
    "\n",
    "final_TotalOrders = pd.DataFrame(final_result)\n",
    "print(final_TotalOrders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "83be154c-2387-4d6a-9de3-5b92a73db2af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name            | Type             | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | criterion       | MSELoss          | 0      | train\n",
      "1 | train_criterion | MSELoss          | 0      | train\n",
      "2 | val_criterion   | MSELoss          | 0      | train\n",
      "3 | train_metrics   | MetricCollection | 0      | train\n",
      "4 | val_metrics     | MetricCollection | 0      | train\n",
      "5 | decomposition   | _SeriesDecomp    | 0      | train\n",
      "6 | linear_seasonal | Linear           | 42     | train\n",
      "7 | linear_trend    | Linear           | 42     | train\n",
      "-------------------------------------------------------------\n",
      "84        Trainable params\n",
      "0         Non-trainable params\n",
      "84        Total params\n",
      "0.000     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 83.42it/s, train_loss=9.18e+8]   "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 83.42it/s, train_loss=9.18e+8]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 116.97it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name            | Type             | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | criterion       | MSELoss          | 0      | train\n",
      "1 | train_criterion | MSELoss          | 0      | train\n",
      "2 | val_criterion   | MSELoss          | 0      | train\n",
      "3 | train_metrics   | MetricCollection | 0      | train\n",
      "4 | val_metrics     | MetricCollection | 0      | train\n",
      "5 | decomposition   | _SeriesDecomp    | 0      | train\n",
      "6 | linear_seasonal | Linear           | 42     | train\n",
      "7 | linear_trend    | Linear           | 42     | train\n",
      "-------------------------------------------------------------\n",
      "84        Trainable params\n",
      "0         Non-trainable params\n",
      "84        Total params\n",
      "0.000     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 228.51it/s, train_loss=1.37e+9] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 228.51it/s, train_loss=1.37e+9]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 276.69it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name            | Type             | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | criterion       | MSELoss          | 0      | train\n",
      "1 | train_criterion | MSELoss          | 0      | train\n",
      "2 | val_criterion   | MSELoss          | 0      | train\n",
      "3 | train_metrics   | MetricCollection | 0      | train\n",
      "4 | val_metrics     | MetricCollection | 0      | train\n",
      "5 | decomposition   | _SeriesDecomp    | 0      | train\n",
      "6 | linear_seasonal | Linear           | 42     | train\n",
      "7 | linear_trend    | Linear           | 42     | train\n",
      "-------------------------------------------------------------\n",
      "84        Trainable params\n",
      "0         Non-trainable params\n",
      "84        Total params\n",
      "0.000     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 126.82it/s, train_loss=1.99e+9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 126.82it/s, train_loss=1.99e+9]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 214.43it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name            | Type             | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | criterion       | MSELoss          | 0      | train\n",
      "1 | train_criterion | MSELoss          | 0      | train\n",
      "2 | val_criterion   | MSELoss          | 0      | train\n",
      "3 | train_metrics   | MetricCollection | 0      | train\n",
      "4 | val_metrics     | MetricCollection | 0      | train\n",
      "5 | decomposition   | _SeriesDecomp    | 0      | train\n",
      "6 | linear_seasonal | Linear           | 42     | train\n",
      "7 | linear_trend    | Linear           | 42     | train\n",
      "-------------------------------------------------------------\n",
      "84        Trainable params\n",
      "0         Non-trainable params\n",
      "84        Total params\n",
      "0.000     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 121.06it/s, train_loss=2.58e+9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 75.33it/s, train_loss=2.58e+9] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 101.64it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name            | Type             | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | criterion       | MSELoss          | 0      | train\n",
      "1 | train_criterion | MSELoss          | 0      | train\n",
      "2 | val_criterion   | MSELoss          | 0      | train\n",
      "3 | train_metrics   | MetricCollection | 0      | train\n",
      "4 | val_metrics     | MetricCollection | 0      | train\n",
      "5 | decomposition   | _SeriesDecomp    | 0      | train\n",
      "6 | linear_seasonal | Linear           | 42     | train\n",
      "7 | linear_trend    | Linear           | 42     | train\n",
      "-------------------------------------------------------------\n",
      "84        Trainable params\n",
      "0         Non-trainable params\n",
      "84        Total params\n",
      "0.000     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 334.39it/s, train_loss=2.91e+9] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 334.39it/s, train_loss=2.91e+9]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 211.53it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name            | Type             | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | criterion       | MSELoss          | 0      | train\n",
      "1 | train_criterion | MSELoss          | 0      | train\n",
      "2 | val_criterion   | MSELoss          | 0      | train\n",
      "3 | train_metrics   | MetricCollection | 0      | train\n",
      "4 | val_metrics     | MetricCollection | 0      | train\n",
      "5 | decomposition   | _SeriesDecomp    | 0      | train\n",
      "6 | linear_seasonal | Linear           | 42     | train\n",
      "7 | linear_trend    | Linear           | 42     | train\n",
      "-------------------------------------------------------------\n",
      "84        Trainable params\n",
      "0         Non-trainable params\n",
      "84        Total params\n",
      "0.000     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 239.63it/s, train_loss=3.27e+9] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 103.12it/s, train_loss=3.27e+9]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name            | Type             | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | criterion       | MSELoss          | 0      | train\n",
      "1 | train_criterion | MSELoss          | 0      | train\n",
      "2 | val_criterion   | MSELoss          | 0      | train\n",
      "3 | train_metrics   | MetricCollection | 0      | train\n",
      "4 | val_metrics     | MetricCollection | 0      | train\n",
      "5 | decomposition   | _SeriesDecomp    | 0      | train\n",
      "6 | linear_seasonal | Linear           | 42     | train\n",
      "7 | linear_trend    | Linear           | 42     | train\n",
      "-------------------------------------------------------------\n",
      "84        Trainable params\n",
      "0         Non-trainable params\n",
      "84        Total params\n",
      "0.000     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 331.83it/s, train_loss=3.46e+9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 125.98it/s, train_loss=3.46e+9]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 74.34it/s] \n",
      "  Orders_Date  Actual        DLinear  Accuracy_NBEATS\n",
      "0  2023-10-01  352135  224680.208409        63.805134\n",
      "1  2023-11-01  349500  214169.694151        61.278882\n",
      "2  2023-12-01  237928  269704.063779       113.355328\n",
      "3  2024-01-01  302400  288206.039787        95.306230\n",
      "4  2024-02-01  287972  242222.269122        84.113132\n",
      "5  2024-03-01  253875  273028.281172       107.544375\n",
      "6  2024-04-01  285937  292846.892618       102.416579\n"
     ]
    }
   ],
   "source": [
    "from darts import TimeSeries\n",
    "from darts.models import DLinearModel\n",
    "import pandas as pd\n",
    "\n",
    "dates = ['2023-10-01', '2023-11-01', '2023-12-01', '2024-01-01', '2024-02-01', '2024-03-01', '2024-04-01']\n",
    "\n",
    "final_result = []\n",
    "for da in dates:\n",
    "    data = {}\n",
    "    Train = df.copy()\n",
    "    series = TimeSeries.from_dataframe(Train, time_col='Orders_Date', value_cols='Sales_Volume')\n",
    "\n",
    "    train, val = series.split_before(pd.Timestamp(da))\n",
    "    Test = df[df['Orders_Date'] == da]\n",
    "    data['Orders_Date'] = da\n",
    "    data['Actual'] = Test['Sales_Volume'].values[0]\n",
    "\n",
    "    model = DLinearModel(input_chunk_length=6, output_chunk_length=6, n_epochs=100)\n",
    "    model.fit(train)\n",
    "    forecast = model.predict(1)\n",
    "    Result = forecast.pd_series().tolist()\n",
    "\n",
    "    data[\"DLinear\"] = Result[0]  # Assuming you want the first value of the forecast\n",
    "    data['Accuracy_NBEATS'] = ((Result[0] * 100) / Test['Sales_Volume'].values[0])\n",
    "    final_result.append(data)\n",
    "\n",
    "final_TotalOrders = pd.DataFrame(final_result)\n",
    "print(final_TotalOrders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "47597a6a-b643-490b-a60d-f8116b215515",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Orders_Date  Actual     SimpleExpo  Accuracy_SimpleExpo\n",
      "0  2023-10-01  352135  265198.096857            75.311485\n",
      "1  2023-11-01  349500  282596.474176            80.857360\n",
      "2  2023-12-01  237928  295982.854230           124.400177\n",
      "3  2024-01-01  302400  284369.699273            94.037599\n",
      "4  2024-02-01  287972  287976.817569           100.001673\n",
      "5  2024-03-01  253875  287975.505897           113.432006\n",
      "6  2024-04-01  285937  281155.049394            98.327621\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.tsa.holtwinters import SimpleExpSmoothing\n",
    "\n",
    "df = df[df['Orders_Date'] > '2022-04-01']\n",
    "final_result = []\n",
    "\n",
    "for da in dates:\n",
    "    data = {}\n",
    "    Train = df[df['Orders_Date'] < da]\n",
    "    Train.set_index('Orders_Date', inplace=True)\n",
    "    Train.index = pd.DatetimeIndex(Train.index).to_period('M')\n",
    "    Test = df[df['Orders_Date'] == da]\n",
    "    \n",
    "    data[\"Orders_Date\"] = da\n",
    "    data['Actual'] = Test['Sales_Volume'].values[0]\n",
    "    \n",
    "    model = SimpleExpSmoothing(Train['Sales_Volume'], initialization_method=\"estimated\").fit(smoothing_level=0.2, optimized=True)\n",
    "    forecast = model.forecast(1)\n",
    "    Result = forecast.values[0]\n",
    "    \n",
    "    data[\"SimpleExpo\"] = Result\n",
    "    data['Accuracy_SimpleExpo'] = ((Result * 100) / Test['Sales_Volume'].values[0])\n",
    "    final_result.append(data)\n",
    "\n",
    "final_TotalOrders = pd.DataFrame(final_result)\n",
    "print(final_TotalOrders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "52b2993f-dccb-4cae-a345-76bbc457dc7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Orders_Date  Actual           Holt  Accuracy_Holt\n",
      "0  2023-10-01  352135  241254.602135      68.511963\n",
      "1  2023-11-01  349500  266520.165441      76.257558\n",
      "2  2023-12-01  237928  291103.723421     122.349502\n",
      "3  2024-01-01  302400  285217.655924      94.318008\n",
      "4  2024-02-01  287972  294376.342392     102.223946\n",
      "5  2024-03-01  253875  298380.051451     117.530301\n",
      "6  2024-04-01  285937  292067.172868     102.143889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Charan\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\holtwinters\\model.py:918: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Charan\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\holtwinters\\model.py:918: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Charan\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\holtwinters\\model.py:918: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Charan\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\holtwinters\\model.py:918: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Charan\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\holtwinters\\model.py:918: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Charan\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\holtwinters\\model.py:918: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Charan\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\holtwinters\\model.py:918: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.tsa.holtwinters import Holt\n",
    "\n",
    "df = df[df['Orders_Date'] > '2022-04-01']\n",
    "final_result = []\n",
    "\n",
    "for da in dates:\n",
    "    data = {}\n",
    "    Train = df[df['Orders_Date'] < da]\n",
    "    Train.set_index('Orders_Date', inplace=True)\n",
    "    Train.index = pd.DatetimeIndex(Train.index).to_period('M')\n",
    "    Test = df[df['Orders_Date'] == da]\n",
    "    \n",
    "    data[\"Orders_Date\"] = da\n",
    "    data['Actual'] = Test['Sales_Volume'].values[0]\n",
    "    \n",
    "    model = Holt(Train['Sales_Volume'], damped_trend=True, initialization_method=\"estimated\").fit(smoothing_level=0.2, smoothing_trend=0.3)\n",
    "    forecast = model.forecast(1)\n",
    "    Result = forecast.values[0]\n",
    "    \n",
    "    data[\"Holt\"] = Result\n",
    "    data['Accuracy_Holt'] = ((Result * 100) / Test['Sales_Volume'].values[0])\n",
    "    final_result.append(data)\n",
    "\n",
    "final_TotalOrders = pd.DataFrame(final_result)\n",
    "print(final_TotalOrders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "65742d4b-e5ba-440f-b917-7e6861bc7d0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Charan\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\holtwinters\\model.py:918: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "09:51:51 - cmdstanpy - INFO - Chain [1] start processing\n",
      "09:51:51 - cmdstanpy - INFO - Chain [1] done processing\n",
      "C:\\Users\\Charan\\anaconda3\\Lib\\site-packages\\prophet\\forecaster.py:1854: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  dates = pd.date_range(\n",
      "C:\\Users\\Charan\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\holtwinters\\model.py:918: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "09:51:51 - cmdstanpy - INFO - Chain [1] start processing\n",
      "09:51:51 - cmdstanpy - INFO - Chain [1] done processing\n",
      "C:\\Users\\Charan\\anaconda3\\Lib\\site-packages\\prophet\\forecaster.py:1854: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  dates = pd.date_range(\n",
      "C:\\Users\\Charan\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\holtwinters\\model.py:918: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "09:51:51 - cmdstanpy - INFO - Chain [1] start processing\n",
      "09:51:51 - cmdstanpy - INFO - Chain [1] done processing\n",
      "C:\\Users\\Charan\\anaconda3\\Lib\\site-packages\\prophet\\forecaster.py:1854: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  dates = pd.date_range(\n",
      "C:\\Users\\Charan\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\holtwinters\\model.py:918: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "09:51:51 - cmdstanpy - INFO - Chain [1] start processing\n",
      "09:51:51 - cmdstanpy - INFO - Chain [1] done processing\n",
      "C:\\Users\\Charan\\anaconda3\\Lib\\site-packages\\prophet\\forecaster.py:1854: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  dates = pd.date_range(\n",
      "C:\\Users\\Charan\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\holtwinters\\model.py:918: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "09:51:51 - cmdstanpy - INFO - Chain [1] start processing\n",
      "09:51:51 - cmdstanpy - INFO - Chain [1] done processing\n",
      "C:\\Users\\Charan\\anaconda3\\Lib\\site-packages\\prophet\\forecaster.py:1854: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  dates = pd.date_range(\n",
      "C:\\Users\\Charan\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\holtwinters\\model.py:918: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "09:51:52 - cmdstanpy - INFO - Chain [1] start processing\n",
      "09:51:52 - cmdstanpy - INFO - Chain [1] done processing\n",
      "C:\\Users\\Charan\\anaconda3\\Lib\\site-packages\\prophet\\forecaster.py:1854: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  dates = pd.date_range(\n",
      "C:\\Users\\Charan\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\holtwinters\\model.py:918: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "09:51:52 - cmdstanpy - INFO - Chain [1] start processing\n",
      "09:51:52 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Orders_Date  Actual     SimpleExpo        Prophet  Average_All_Algorithms  \\\n",
      "0  2023-10-01  352135  275882.313986  252188.941964           264035.627975   \n",
      "1  2023-11-01  349500  287840.354228  277156.608546           282498.481387   \n",
      "2  2023-12-01  237928  294904.355847  296432.229661           295668.292754   \n",
      "3  2024-01-01  302400  290028.239812  284386.003107           287207.121459   \n",
      "4  2024-02-01  287972  291087.032311  289376.095718           290231.564015   \n",
      "5  2024-03-01  253875  290820.443500  288239.959405           289530.201452   \n",
      "6  2024-04-01  285937  286118.255040  283391.728517           284754.991778   \n",
      "\n",
      "   Accuracy_All_Algorithms  \n",
      "0                74.981365  \n",
      "1                80.829322  \n",
      "2               124.267969  \n",
      "3                94.975900  \n",
      "4               100.784647  \n",
      "5               114.044392  \n",
      "6                99.586619  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Charan\\anaconda3\\Lib\\site-packages\\prophet\\forecaster.py:1854: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  dates = pd.date_range(\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.tsa.api import SimpleExpSmoothing\n",
    "from prophet import Prophet\n",
    "dates = ['2023-10-01', '2023-11-01', '2023-12-01', '2024-01-01', '2024-02-01', '2024-03-01', '2024-04-01']\n",
    "\n",
    "final_result = []\n",
    "for da in dates:\n",
    "    data = {}\n",
    "    Train = df[df['Orders_Date'] < da]\n",
    "    Train.set_index('Orders_Date', inplace=True)\n",
    "    Train.index = pd.DatetimeIndex(Train.index).to_period('M')\n",
    "    Test = df[df['Orders_Date'] == da]\n",
    "    \n",
    "    data[\"Orders_Date\"] = da\n",
    "    data['Actual'] = Test['Sales_Volume'].values[0]\n",
    "    \n",
    "    model = SimpleExpSmoothing(Train['Sales_Volume'], initialization_method=\"estimated\").fit()\n",
    "    \n",
    "    forecast = model.forecast(1)\n",
    "    Result_1 = forecast.values[0]\n",
    "    \n",
    "    data[\"SimpleExpo\"] = Result_1\n",
    "\n",
    "    Train = df[(df['Orders_Date']>='2022-08-01') & (df['Orders_Date']<da)]\n",
    "    Train=Train.rename(columns={'Orders_Date' : 'ds', 'Sales_Volume' : 'y'})\n",
    "    Test=df[(df['Orders_Date']==da)]\n",
    "    data[\"Orders_Date\"] = da\n",
    "    data['Actual'] = Test['Sales_Volume'].values[0]\n",
    "\n",
    "    model = Prophet()\n",
    "    model.fit(Train)\n",
    "    future=model.make_future_dataframe(periods=2,freq='M').tail(2)\n",
    "    forecast=model.predict(future)\n",
    "    forecast[['ds','yhat']]\n",
    "\n",
    "    Result_2=sum(forecast['yhat'])/len(forecast)\n",
    "    data[\"Prophet\"] = Result_2\n",
    "\n",
    "    data['Average_All_Algorithms']=(Result_1+Result_2)/2\n",
    "    data['Accuracy_All_Algorithms']=((((Result_1+Result_2)/2)*100)/Test['Sales_Volume'].values[0])\n",
    "\n",
    "    final_result.append(data)\n",
    "\n",
    "final_TotalOrders = pd.DataFrame(final_result)\n",
    "print(final_TotalOrders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "63100543-0de6-4502-b390-fdc01bd0ee91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Orders_Date  Actual     SimpleExpo           Holt  Average_All_Algorithms  \\\n",
      "0  2023-10-01  352135  275882.313986  243130.771279           259506.542633   \n",
      "1  2023-11-01  349500  287840.354228  268466.416779           278153.385503   \n",
      "2  2023-12-01  237928  294904.355847  293604.015443           294254.185645   \n",
      "3  2024-01-01  302400  290028.239812  287959.839676           288994.039744   \n",
      "4  2024-02-01  287972  291087.032311  297327.709509           294207.370910   \n",
      "5  2024-03-01  253875  290820.443500  301408.121383           296114.282441   \n",
      "6  2024-04-01  285937  286118.255040  294932.987003           290525.621021   \n",
      "\n",
      "   Accuracy_All_Algorithms  \n",
      "0                73.695186  \n",
      "1                79.586090  \n",
      "2               123.673626  \n",
      "3                95.566812  \n",
      "4               102.165270  \n",
      "5               116.637827  \n",
      "6               101.604766  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Charan\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\holtwinters\\model.py:918: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Charan\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\holtwinters\\model.py:918: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Charan\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\holtwinters\\model.py:918: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Charan\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\holtwinters\\model.py:918: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Charan\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\holtwinters\\model.py:918: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Charan\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\holtwinters\\model.py:918: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Charan\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\holtwinters\\model.py:918: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Charan\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\holtwinters\\model.py:918: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Charan\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\holtwinters\\model.py:918: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Charan\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\holtwinters\\model.py:918: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Charan\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\holtwinters\\model.py:918: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Charan\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\holtwinters\\model.py:918: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Charan\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\holtwinters\\model.py:918: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Charan\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\holtwinters\\model.py:918: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.tsa.api import SimpleExpSmoothing\n",
    "from statsmodels.tsa.api import Holt\n",
    "dates = ['2023-10-01', '2023-11-01', '2023-12-01', '2024-01-01', '2024-02-01', '2024-03-01', '2024-04-01']\n",
    "\n",
    "final_result = []\n",
    "for da in dates:\n",
    "    data = {}\n",
    "    Train = df[df['Orders_Date'] < da]\n",
    "    Train.set_index('Orders_Date', inplace=True)\n",
    "    Train.index = pd.DatetimeIndex(Train.index).to_period('M')\n",
    "    Test = df[df['Orders_Date'] == da]\n",
    "    \n",
    "    data[\"Orders_Date\"] = da\n",
    "    data['Actual'] = Test['Sales_Volume'].values[0]\n",
    "    \n",
    "    model = SimpleExpSmoothing(Train['Sales_Volume'], initialization_method=\"estimated\").fit()\n",
    "    \n",
    "    forecast = model.forecast(1)\n",
    "    Result_1 = forecast.values[0]\n",
    "    \n",
    "    data[\"SimpleExpo\"] = Result_1\n",
    "\n",
    "    Train = df[df['Orders_Date'] < da]\n",
    "    Train.set_index('Orders_Date', inplace=True)\n",
    "    Train.index = pd.DatetimeIndex(Train.index).to_period('M')\n",
    "    Test = df[df['Orders_Date'] == da]\n",
    "    \n",
    "    data[\"Orders_Date\"] = da\n",
    "    data['Actual'] = Test['Sales_Volume'].values[0]\n",
    "    \n",
    "    model = Holt(Train['Sales_Volume'],damped_trend=True,exponential=True, initialization_method=\"estimated\").fit(smoothing_level=0.2,smoothing_trend=0.3)\n",
    "    forecast = model.forecast(1)\n",
    "    Result_2 = forecast.values[0]\n",
    "    \n",
    "    data[\"Holt\"] = Result_2\n",
    "    data['Average_All_Algorithms']=(Result_1+Result_2)/2\n",
    "    data['Accuracy_All_Algorithms']=((((Result_1+Result_2)/2)*100)/Test['Sales_Volume'].values[0])\n",
    "\n",
    "    final_result.append(data)\n",
    "\n",
    "final_TotalOrders = pd.DataFrame(final_result)\n",
    "print(final_TotalOrders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0dff989d-7eb2-4479-91c5-4923f1de46bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "09:52:40 - cmdstanpy - INFO - Chain [1] start processing\n",
      "09:52:40 - cmdstanpy - INFO - Chain [1] done processing\n",
      "C:\\Users\\Charan\\anaconda3\\Lib\\site-packages\\prophet\\forecaster.py:1854: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  dates = pd.date_range(\n",
      "C:\\Users\\Charan\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\holtwinters\\model.py:918: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "09:52:40 - cmdstanpy - INFO - Chain [1] start processing\n",
      "09:52:40 - cmdstanpy - INFO - Chain [1] done processing\n",
      "C:\\Users\\Charan\\anaconda3\\Lib\\site-packages\\prophet\\forecaster.py:1854: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  dates = pd.date_range(\n",
      "C:\\Users\\Charan\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\holtwinters\\model.py:918: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "09:52:40 - cmdstanpy - INFO - Chain [1] start processing\n",
      "09:52:41 - cmdstanpy - INFO - Chain [1] done processing\n",
      "C:\\Users\\Charan\\anaconda3\\Lib\\site-packages\\prophet\\forecaster.py:1854: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  dates = pd.date_range(\n",
      "C:\\Users\\Charan\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\holtwinters\\model.py:918: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "09:52:41 - cmdstanpy - INFO - Chain [1] start processing\n",
      "09:52:41 - cmdstanpy - INFO - Chain [1] done processing\n",
      "C:\\Users\\Charan\\anaconda3\\Lib\\site-packages\\prophet\\forecaster.py:1854: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  dates = pd.date_range(\n",
      "C:\\Users\\Charan\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\holtwinters\\model.py:918: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "09:52:41 - cmdstanpy - INFO - Chain [1] start processing\n",
      "09:52:41 - cmdstanpy - INFO - Chain [1] done processing\n",
      "C:\\Users\\Charan\\anaconda3\\Lib\\site-packages\\prophet\\forecaster.py:1854: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  dates = pd.date_range(\n",
      "C:\\Users\\Charan\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\holtwinters\\model.py:918: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "09:52:41 - cmdstanpy - INFO - Chain [1] start processing\n",
      "09:52:41 - cmdstanpy - INFO - Chain [1] done processing\n",
      "C:\\Users\\Charan\\anaconda3\\Lib\\site-packages\\prophet\\forecaster.py:1854: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  dates = pd.date_range(\n",
      "C:\\Users\\Charan\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\holtwinters\\model.py:918: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "09:52:41 - cmdstanpy - INFO - Chain [1] start processing\n",
      "09:52:41 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Orders_Date  Actual        Prophet           Holt  Average_All_Algorithms  \\\n",
      "0  2023-10-01  352135  252188.941964  243130.771279           247659.856622   \n",
      "1  2023-11-01  349500  277156.608546  268466.416779           272811.512662   \n",
      "2  2023-12-01  237928  296432.229661  293604.015443           295018.122552   \n",
      "3  2024-01-01  302400  284386.003107  287959.839676           286172.921391   \n",
      "4  2024-02-01  287972  289376.095718  297327.709509           293351.902614   \n",
      "5  2024-03-01  253875  288239.959405  301408.121383           294824.040394   \n",
      "6  2024-04-01  285937  283391.728517  294932.987003           289162.357760   \n",
      "\n",
      "   Accuracy_All_Algorithms  \n",
      "0                70.330940  \n",
      "1                78.057657  \n",
      "2               123.994705  \n",
      "3                94.633903  \n",
      "4               101.868203  \n",
      "5               116.129607  \n",
      "6               101.127996  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Charan\\anaconda3\\Lib\\site-packages\\prophet\\forecaster.py:1854: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  dates = pd.date_range(\n",
      "C:\\Users\\Charan\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\holtwinters\\model.py:918: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.tsa.api import Holt\n",
    "from prophet import Prophet\n",
    "dates = ['2023-10-01', '2023-11-01', '2023-12-01', '2024-01-01', '2024-02-01', '2024-03-01','2024-04-01']\n",
    "\n",
    "final_result=[]\n",
    "for da in dates:\n",
    "    data = {}\n",
    "    Train = df[(df['Orders_Date']>='2022-08-01') & (df['Orders_Date']<da)]\n",
    "    Train=Train.rename(columns={'Orders_Date' : 'ds', 'Sales_Volume' : 'y'})\n",
    "    Test=df[(df['Orders_Date']==da)]\n",
    "    data[\"Orders_Date\"] = da\n",
    "    data['Actual'] = Test['Sales_Volume'].values[0]\n",
    "\n",
    "    model = Prophet()\n",
    "    model.fit(Train)\n",
    "    future=model.make_future_dataframe(periods=2,freq='M').tail(2)\n",
    "    forecast=model.predict(future)\n",
    "    forecast[['ds','yhat']]\n",
    "\n",
    "    Result_1=sum(forecast['yhat'])/len(forecast)\n",
    "    data[\"Prophet\"] = Result_1\n",
    "\n",
    "    Train = df[df['Orders_Date'] < da]\n",
    "    Train.set_index('Orders_Date', inplace=True)\n",
    "    Train.index = pd.DatetimeIndex(Train.index).to_period('M')\n",
    "    Test = df[df['Orders_Date'] == da]\n",
    "    \n",
    "    data[\"Orders_Date\"] = da\n",
    "    data['Actual'] = Test['Sales_Volume'].values[0]\n",
    "    \n",
    "    model = Holt(Train['Sales_Volume'],damped_trend=True,exponential=True, initialization_method=\"estimated\").fit(smoothing_level=0.2,smoothing_trend=0.3)\n",
    "    forecast = model.forecast(1)\n",
    "    Result_2 = forecast.values[0]\n",
    "    \n",
    "    data[\"Holt\"] = Result_2\n",
    "    data['Average_All_Algorithms']=(Result_1+Result_2)/2\n",
    "    data['Accuracy_All_Algorithms']=((((Result_1+Result_2)/2)*100)/Test['Sales_Volume'].values[0])\n",
    "\n",
    "    final_result.append(data)\n",
    "\n",
    "final_TotalOrders = pd.DataFrame(final_result)\n",
    "print(final_TotalOrders)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fbe3514e-be46-4c91-9744-0a147e5440a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Charan\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\holtwinters\\model.py:918: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Charan\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\holtwinters\\model.py:918: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Charan\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\holtwinters\\model.py:918: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Charan\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\holtwinters\\model.py:918: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Charan\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\holtwinters\\model.py:918: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Charan\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\holtwinters\\model.py:918: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Charan\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\holtwinters\\model.py:918: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Charan\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\holtwinters\\model.py:918: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Charan\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\holtwinters\\model.py:918: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Charan\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\holtwinters\\model.py:918: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Orders_Date  Actual     SimpleExpo    Holt-winter  Average_All_Algorithms  \\\n",
      "0  2023-10-01  352135  275882.313986  258033.492972           266957.903479   \n",
      "1  2023-11-01  349500  287840.354228  261814.264105           274827.309166   \n",
      "2  2023-12-01  237928  294904.355847  236334.246631           265619.301239   \n",
      "3  2024-01-01  302400  290028.239812  244304.948748           267166.594280   \n",
      "4  2024-02-01  287972  291087.032311  280195.321254           285641.176783   \n",
      "5  2024-03-01  253875  290820.443500  265252.656678           278036.550089   \n",
      "6  2024-04-01  285937  286118.255040  218589.262131           252353.758585   \n",
      "\n",
      "   Accuracy_All_Algorithms  \n",
      "0                75.811238  \n",
      "1                78.634423  \n",
      "2               111.638521  \n",
      "3                88.348741  \n",
      "4                99.190608  \n",
      "5               109.517105  \n",
      "6                88.255021  \n"
     ]
    }
   ],
   "source": [
    "from statsmodels.tsa.api import SimpleExpSmoothing\n",
    "from statsmodels.tsa.api import ExponentialSmoothing\n",
    "dates = ['2023-10-01', '2023-11-01', '2023-12-01', '2024-01-01', '2024-02-01', '2024-03-01', '2024-04-01']\n",
    "\n",
    "final_result = []\n",
    "for da in dates:\n",
    "    data = {}\n",
    "    Train = df[df['Orders_Date'] < da]\n",
    "    Train.set_index('Orders_Date', inplace=True)\n",
    "    Train.index = pd.DatetimeIndex(Train.index).to_period('M')\n",
    "    Test = df[df['Orders_Date'] == da]\n",
    "    \n",
    "    data[\"Orders_Date\"] = da\n",
    "    data['Actual'] = Test['Sales_Volume'].values[0]\n",
    "    \n",
    "    model = SimpleExpSmoothing(Train['Sales_Volume'], initialization_method=\"estimated\").fit()\n",
    "    \n",
    "    forecast = model.forecast(1)\n",
    "    Result_1 = forecast.values[0]\n",
    "    \n",
    "    data[\"SimpleExpo\"] = Result_1\n",
    "    \n",
    "    Train = df[df['Orders_Date'] < da]\n",
    "    Train.set_index('Orders_Date', inplace=True)\n",
    "    Train.index = pd.DatetimeIndex(Train.index).to_period('M')\n",
    "    Test = df[df['Orders_Date'] == da]\n",
    "    \n",
    "    data[\"Orders_Date\"] = da\n",
    "    data['Actual'] = Test['Sales_Volume'].values[0]\n",
    "    \n",
    "    model = ExponentialSmoothing(Train['Sales_Volume'],seasonal_periods=4,trend=\"add\", seasonal=\"mul\",damped_trend=True,use_boxcox=True,initialization_method=\"estimated\").fit()\n",
    "    forecast = model.forecast(1)\n",
    "    Result_2 = forecast.values[0]\n",
    "    \n",
    "    data[\"Holt-winter\"] = Result_2\n",
    "    data['Average_All_Algorithms']=(Result_1+Result_2)/2\n",
    "    data['Accuracy_All_Algorithms']=((((Result_1+Result_2)/2)*100)/Test['Sales_Volume'].values[0])\n",
    "\n",
    "    final_result.append(data)\n",
    "\n",
    "final_TotalOrders = pd.DataFrame(final_result)\n",
    "print(final_TotalOrders)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "14f9712f-eb4c-40a9-838f-3f2ee8c97c98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Orders_Date  Actual     SimpleExpo         SARIMA  Average_All_Algorithms  \\\n",
      "0  2023-10-01  352135  275882.313986  288167.670899           282024.992442   \n",
      "1  2023-11-01  349500  287840.354228  326367.614075           307103.984151   \n",
      "2  2023-12-01  237928  294904.355847  325566.378838           310235.367343   \n",
      "3  2024-01-01  302400  290028.239812  219222.818617           254625.529214   \n",
      "4  2024-02-01  287972  291087.032311  280973.441529           286030.236920   \n",
      "5  2024-03-01  253875  290820.443500  268169.561973           279495.002736   \n",
      "6  2024-04-01  285937  286118.255040  236391.527097           261254.891068   \n",
      "\n",
      "   Accuracy_All_Algorithms  \n",
      "0                80.090020  \n",
      "1                87.869523  \n",
      "2               130.390441  \n",
      "3                84.201564  \n",
      "4                99.325711  \n",
      "5               110.091582  \n",
      "6                91.367991  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Charan\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\holtwinters\\model.py:918: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Charan\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\holtwinters\\model.py:918: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Charan\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\holtwinters\\model.py:918: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Charan\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\holtwinters\\model.py:918: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Charan\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\holtwinters\\model.py:918: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Charan\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\holtwinters\\model.py:918: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Charan\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\holtwinters\\model.py:918: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.tsa.api import SimpleExpSmoothing\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from pmdarima import auto_arima\n",
    "\n",
    "dates = ['2023-10-01', '2023-11-01', '2023-12-01', '2024-01-01', '2024-02-01', '2024-03-01', '2024-04-01']\n",
    "\n",
    "final_result = []\n",
    "for da in dates:\n",
    "    data = {}\n",
    "    Train = df[df['Orders_Date'] < da]\n",
    "    Train.set_index('Orders_Date', inplace=True)\n",
    "    Train.index = pd.DatetimeIndex(Train.index).to_period('M')\n",
    "    Test = df[df['Orders_Date'] == da]\n",
    "    \n",
    "    data[\"Orders_Date\"] = da\n",
    "    data['Actual'] = Test['Sales_Volume'].values[0]\n",
    "    \n",
    "    model = SimpleExpSmoothing(Train['Sales_Volume'], initialization_method=\"estimated\").fit()\n",
    "    \n",
    "    forecast = model.forecast(1)\n",
    "    Result_1 = forecast.values[0]\n",
    "    \n",
    "    data[\"SimpleExpo\"] = Result_1\n",
    "    Train = df[df['Orders_Date'] < da]\n",
    "    Train.set_index('Orders_Date', inplace=True)\n",
    "    Train.index = pd.DatetimeIndex(Train.index).to_period('M')\n",
    "    Test = df[df['Orders_Date'] == da]\n",
    "    \n",
    "    data[\"Orders_Date\"] = da\n",
    "    data['Actual'] = Test['Sales_Volume'].values[0]\n",
    "\n",
    "    model=SARIMAX(Train['Sales_Volume'],order=(1,0,0),seasonal_order=(0,0,0,4)).fit()\n",
    "    forecast=model.predict(start=len(Train),end=len(Train)+1,dynamic=True)\n",
    "    Result_2 = forecast.values[0]\n",
    "    \n",
    "    data[\"SARIMA\"] = Result_2\n",
    "    data['Average_All_Algorithms']=(Result_1+Result_2)/2\n",
    "    data['Accuracy_All_Algorithms']=((((Result_1+Result_2)/2)*100)/Test['Sales_Volume'].values[0])\n",
    "\n",
    "    final_result.append(data)\n",
    "\n",
    "final_TotalOrders = pd.DataFrame(final_result)\n",
    "print(final_TotalOrders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aabd0a3-04fe-4dc4-8ed0-cdb99b38ea75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.api import Holt\n",
    "from statsmodels.tsa.api import ExponentialSmoothing\n",
    "dates = ['2023-10-01', '2023-11-01', '2023-12-01', '2024-01-01', '2024-02-01', '2024-03-01','2024-04-01']\n",
    "\n",
    "final_result=[]\n",
    "for da in dates:\n",
    "    data = {}\n",
    "    Train = df[df['Orders_Date'] < da]\n",
    "    Train.set_index('Orders_Date', inplace=True)\n",
    "    Train.index = pd.DatetimeIndex(Train.index).to_period('M')\n",
    "    Test = df[df['Orders_Date'] == da]\n",
    "    \n",
    "    data[\"Orders_Date\"] = da\n",
    "    data['Actual'] = Test['Sales_Volume'].values[0]\n",
    "    \n",
    "    model = Holt(Train['Sales_Volume'],damped_trend=True,exponential=True, initialization_method=\"estimated\").fit(smoothing_level=0.2,smoothing_trend=0.3)\n",
    "    forecast = model.forecast(1)\n",
    "    Result_1 = forecast.values[0]\n",
    "    \n",
    "    data[\"Holt\"] = Result_1\n",
    "    Train = df[df['Orders_Date'] < da]\n",
    "    Train.set_index('Orders_Date', inplace=True)\n",
    "    Train.index = pd.DatetimeIndex(Train.index).to_period('M')\n",
    "    Test = df[df['Orders_Date'] == da]\n",
    "    \n",
    "    data[\"Orders_Date\"] = da\n",
    "    data['Actual'] = Test['Sales_Volume'].values[0]\n",
    "    \n",
    "    model = ExponentialSmoothing(Train['Sales_Volume'],seasonal_periods=4,trend=\"add\", seasonal=\"mul\",damped_trend=True,use_boxcox=True,initialization_method=\"estimated\").fit()\n",
    "    forecast = model.forecast(1)\n",
    "    Result_2 = forecast.values[0]\n",
    "    \n",
    "    data[\"Holt-winter\"] = Result_2\n",
    "    data['Average_All_Algorithms']=(Result_1+Result_2)/2\n",
    "    data['Accuracy_All_Algorithms']=((((Result_1+Result_2)/2)*100)/Test['Sales_Volume'].values[0])\n",
    "\n",
    "    final_result.append(data)\n",
    "\n",
    "final_TotalOrders = pd.DataFrame(final_result)\n",
    "print(final_TotalOrders)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
